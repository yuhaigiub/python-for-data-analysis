{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# options\n",
    "pd.options.display.max_rows = 10\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series data is an important form of structured data in many different fields\n",
    "# such as finance, economics, ecology, neuroscience, and physics\n",
    "# anything that is observed or measured at many points in time forms a time series\n",
    "# many time series are 'fixed frequency', which is to say that data points occur at regular intervals according to some rule\n",
    "# time seires can also be 'irregular' without a fixed unit of time or offset between units\n",
    "# how you mark and refer to time series data depends on the application \n",
    "# you may have one of the following:\n",
    "#   'Timestamps': specific instants in time\n",
    "#   'Fixed periods': such as the month January 2007 or the full year 2010\n",
    "#   'Intervals' of time: indicated by a start and end timestamp. 'Periods' can be thought of as special cases of intervals\n",
    "#   Experiment or elapsed time; each timestamp is a measure of time relative to a particular start time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.1 Date and Time Data Types and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-21 16:32:17.580838\n",
      "2022 3 21\n"
     ]
    }
   ],
   "source": [
    "# the Python standard library includes data types for date and time data as well as calendar-related functionality \n",
    "# the 'datetime', 'date' and 'calendar' modules are the main places to start\n",
    "\n",
    "# the datetime.datetime is widely used\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "print(now)\n",
    "print(now.year, now.month, now.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.timedelta'>\n",
      "926 days, 15:45:00\n",
      "926\n",
      "56700\n"
     ]
    }
   ],
   "source": [
    "# 'datetime' stores both date and time down to the microsecond\n",
    "# 'timedelta' represents the temporal difference between two 'datetime' objects\n",
    "\n",
    "delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)\n",
    "print(type(delta))\n",
    "print(delta)\n",
    "print(delta.days)\n",
    "print(delta.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-19 00:00:00\n",
      "2010-12-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# you can add (or subtract) a 'timedelta' or multiple thereof to a 'datetime' object to yield a new shifted object\n",
    "from datetime import timedelta\n",
    "\n",
    "start = datetime(2011, 1, 7) # 7/1/2011\n",
    "\n",
    "print(start + timedelta(12)) # after 12 days\n",
    "print(start - 2 * timedelta(12)) # before 24 days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1.1 Converting Betwwen String and Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-03 00:00:00\n",
      "2011-01-03\n"
     ]
    }
   ],
   "source": [
    "# you can format 'datetime' objects and pandas 'Timestamp' objects as string \n",
    "# using 'str' or the strftime() method, passing a format specification\n",
    "\n",
    "stamp = datetime(2011, 1, 3) \n",
    "print(str(stamp))\n",
    "print(stamp.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-03 00:00:00\n",
      "[datetime.datetime(2011, 7, 6, 0, 0), datetime.datetime(2011, 8, 6, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "# you can use these same format codes to convert strings to dates using datetime.strptime()\n",
    "\n",
    "value = '2011-01-03'\n",
    "print(datetime.strptime(value, '%Y-%m-%d'))\n",
    "datestrs = ['7/6/2011', '8/6/2011']\n",
    "print([datetime.strptime(x, '%m/%d/%Y') for x in datestrs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-03 00:00:00\n",
      "1997-01-31 22:45:00\n",
      "2011-12-06 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# datetime.strptime() can be a good way to parse a date with a known format\n",
    "# however, it can be annoying to have to write a format specification each time, especially for common date formats\n",
    "# you can use the parser.parse() method in the 3rd-party 'dateutil' package (installed automatically when you install pandas)\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "print(parse('2011-01-03'))\n",
    "\n",
    "# 'dateutil' is capable of parsing most human-intelligible date representations\n",
    "print(parse('Jan 31, 1997 10:45 PM'))\n",
    "\n",
    "# in international locales, day appearing before month is very common\n",
    "# you can pass 'dayfirst=True' to indicate this\n",
    "print(parse('6/12/2011', dayfirst=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas is generally oriented toward working with arrays of dates, whether used as an axis index or a column in a DataFrame\n",
    "# the to_datetime() method parses many different kinds of date representations\n",
    "\n",
    "datestrs = ['2011-07-06 12:00:00', '2011-08-06 00:00:00']\n",
    "pd.to_datetime(datestrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00', 'NaT'], dtype='datetime64[ns]', freq=None)\n",
      "NaT\n",
      "[False, False, True]\n"
     ]
    }
   ],
   "source": [
    "# it also handles values that should be considered missing (None, empty string, etc.)\n",
    "\n",
    "idx = pd.to_datetime(datestrs + [None])\n",
    "print(idx)\n",
    "print(idx[2]) # NaT (Not a Time) is pandas's null value for timestamp data\n",
    "print(list(pd.isnull(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.2 Time Series Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.204708\n",
       "2011-01-05    0.478943\n",
       "2011-01-07   -0.519439\n",
       "2011-01-08   -0.555730\n",
       "2011-01-10    1.965781\n",
       "2011-01-12    1.393406\n",
       "dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a basic kind of time series object in pandas is a Series indexed by timestamps\n",
    "# which is often represented external to pandas as Python strings or 'datetime' object\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "dates = [datetime(2011, 1, 2), datetime(2011, 1, 5),\n",
    "         datetime(2011, 1, 7), datetime(2011, 1, 8),\n",
    "         datetime(2011, 1, 10), datetime(2011, 1, 12)]\n",
    "\n",
    "ts = pd.Series(np.random.randn(6), index=dates)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-01-02', '2011-01-05', '2011-01-07', '2011-01-08',\n",
       "               '2011-01-10', '2011-01-12'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# under the hood, these 'datetime' objects have been put in a 'DatetimeIndex'\n",
    "\n",
    "ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.409415\n",
       "2011-01-05         NaN\n",
       "2011-01-07   -1.038877\n",
       "2011-01-08         NaN\n",
       "2011-01-10    3.931561\n",
       "2011-01-12         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# like other Series, arithmetic operations between differently indexed time series automatically align on the dates\n",
    "\n",
    "ts + ts[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas stores timestamps using Numpy's 'datetime64' data type at the nanosecond resolution\n",
    "\n",
    "ts.index.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-01-02 00:00:00')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar values from a 'DatetimeIndex' are pandas 'Timestamp' objects\n",
    "# a 'Timestamp' can be substituted anywhere you would use a 'datetime' object\n",
    "# additionally, it can store frequency information (if any) and understands how to do time zone conversions and other kinds of manipulations\n",
    "\n",
    "stamp = ts.index[0]\n",
    "stamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2.1 Indexing, Selection, Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5194387150567381"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time series behaves like any other pandas.Series when you are indexing and selecting data based on label\n",
    "\n",
    "stamp = ts.index[2]\n",
    "ts[stamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9657805725027142\n",
      "1.9657805725027142\n"
     ]
    }
   ],
   "source": [
    "# as a convenience, you can also pass a string that is interpretable as a date\n",
    "print(ts['1/10/2011'])\n",
    "print(ts['20110110'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    0.092908\n",
       "2000-01-02    0.281746\n",
       "2000-01-03    0.769023\n",
       "2000-01-04    1.246435\n",
       "2000-01-05    1.007189\n",
       "                ...   \n",
       "2002-09-22    0.930944\n",
       "2002-09-23   -0.811676\n",
       "2002-09-24   -1.830156\n",
       "2002-09-25   -0.138730\n",
       "2002-09-26    0.334088\n",
       "Freq: D, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for longer time series, a year or only a year and month can be passed to easily select slices of data\n",
    "\n",
    "longer_ts = pd.Series(np.random.randn(1000),\n",
    "                      index=pd.date_range('1/1/2000', periods=1000))\n",
    "longer_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-01-01    1.599534\n",
       "2001-01-02    0.474071\n",
       "2001-01-03    0.151326\n",
       "2001-01-04   -0.542173\n",
       "2001-01-05   -0.475496\n",
       "                ...   \n",
       "2001-12-27    0.057874\n",
       "2001-12-28   -0.433739\n",
       "2001-12-29    0.092698\n",
       "2001-12-30   -1.397820\n",
       "2001-12-31    1.457823\n",
       "Freq: D, Length: 365, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here, the string '2001' is interpret as a year and selects that time period\n",
    "\n",
    "longer_ts['2001'] # get all data in year=2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-05-01   -0.622547\n",
       "2001-05-02    0.936289\n",
       "2001-05-03    0.750018\n",
       "2001-05-04   -0.056715\n",
       "2001-05-05    2.300675\n",
       "                ...   \n",
       "2001-05-27    0.235477\n",
       "2001-05-28    0.111835\n",
       "2001-05-29   -1.251504\n",
       "2001-05-30   -2.949343\n",
       "2001-05-31    0.634634\n",
       "Freq: D, Length: 31, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this could also works if you specify the month\n",
    "\n",
    "longer_ts['2001-05'] # get all data in May-2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.204708\n",
       "2011-01-05    0.478943\n",
       "2011-01-07   -0.519439\n",
       "2011-01-08   -0.555730\n",
       "2011-01-10    1.965781\n",
       "2011-01-12    1.393406\n",
       "dtype: float64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slicing with 'datetime' object works as well\n",
    "\n",
    "ts[datetime(2011, 1, 1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-01-02   -0.204708\n",
      "2011-01-05    0.478943\n",
      "2011-01-07   -0.519439\n",
      "2011-01-08   -0.555730\n",
      "2011-01-10    1.965781\n",
      "2011-01-12    1.393406\n",
      "dtype: float64\n",
      "----------------------------\n",
      "2011-01-07   -0.519439\n",
      "2011-01-08   -0.555730\n",
      "2011-01-10    1.965781\n",
      "dtype: float64\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# because most time series data is ordered chronologically\n",
    "# you can slice with timestamps not contained in a time series to perform a range query\n",
    "\n",
    "print(ts)\n",
    "print('----------------------------')\n",
    "print(ts['1/6/2011':'1/11/2011'])\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -0.204708\n",
       "2011-01-05    0.478943\n",
       "2011-01-07   -0.519439\n",
       "2011-01-08   -0.555730\n",
       "dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as before, you can pass either a string date, datetime, or timestamp\n",
    "# remember that slicing in this manner produces views on the source time series like slicing Numpy arrays\n",
    "# this means that no data is copied and modifications on the slice will be reflected in the original data\n",
    "\n",
    "# there is an equivalent instance method, truncate()\n",
    "# that slices a Series between two dates\n",
    "ts.truncate(after='1/9/2011') # remove all days after Jan 9, 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Texas</th>\n",
       "      <th>New York</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>0.488675</td>\n",
       "      <td>-0.178098</td>\n",
       "      <td>2.122315</td>\n",
       "      <td>0.061192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>0.884111</td>\n",
       "      <td>-0.608506</td>\n",
       "      <td>-0.072052</td>\n",
       "      <td>0.544066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-19</th>\n",
       "      <td>0.323886</td>\n",
       "      <td>-1.683325</td>\n",
       "      <td>0.526860</td>\n",
       "      <td>1.858791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-26</th>\n",
       "      <td>-0.548419</td>\n",
       "      <td>-0.279397</td>\n",
       "      <td>-0.021299</td>\n",
       "      <td>-0.287990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-02</th>\n",
       "      <td>0.089175</td>\n",
       "      <td>0.522858</td>\n",
       "      <td>0.572796</td>\n",
       "      <td>-1.760372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-10-31</th>\n",
       "      <td>-0.054630</td>\n",
       "      <td>-0.656506</td>\n",
       "      <td>-1.550087</td>\n",
       "      <td>-0.044347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-07</th>\n",
       "      <td>0.681470</td>\n",
       "      <td>-0.953726</td>\n",
       "      <td>-1.857016</td>\n",
       "      <td>0.449495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-14</th>\n",
       "      <td>-0.061732</td>\n",
       "      <td>1.233914</td>\n",
       "      <td>0.705830</td>\n",
       "      <td>-1.309077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-21</th>\n",
       "      <td>-1.537380</td>\n",
       "      <td>0.531551</td>\n",
       "      <td>2.047573</td>\n",
       "      <td>0.446691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-11-28</th>\n",
       "      <td>-0.223556</td>\n",
       "      <td>0.092835</td>\n",
       "      <td>0.716076</td>\n",
       "      <td>0.657198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Colorado     Texas  New York      Ohio\n",
       "2000-01-05  0.488675 -0.178098  2.122315  0.061192\n",
       "2000-01-12  0.884111 -0.608506 -0.072052  0.544066\n",
       "2000-01-19  0.323886 -1.683325  0.526860  1.858791\n",
       "2000-01-26 -0.548419 -0.279397 -0.021299 -0.287990\n",
       "2000-02-02  0.089175  0.522858  0.572796 -1.760372\n",
       "...              ...       ...       ...       ...\n",
       "2001-10-31 -0.054630 -0.656506 -1.550087 -0.044347\n",
       "2001-11-07  0.681470 -0.953726 -1.857016  0.449495\n",
       "2001-11-14 -0.061732  1.233914  0.705830 -1.309077\n",
       "2001-11-21 -1.537380  0.531551  2.047573  0.446691\n",
       "2001-11-28 -0.223556  0.092835  0.716076  0.657198\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all of this holds true for DataFrame as well, indexing on its rows\n",
    "\n",
    "dates = pd.date_range('1/1/2000', periods=100, freq='W-WED')\n",
    "long_df = pd.DataFrame(np.random.randn(100, 4),\n",
    "                       index=dates,\n",
    "                       columns=['Colorado', 'Texas', 'New York', 'Ohio'])\n",
    "long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Texas</th>\n",
       "      <th>New York</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-05-02</th>\n",
       "      <td>-0.006045</td>\n",
       "      <td>0.490094</td>\n",
       "      <td>-0.277186</td>\n",
       "      <td>-0.707213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-09</th>\n",
       "      <td>-0.560107</td>\n",
       "      <td>2.735527</td>\n",
       "      <td>0.927335</td>\n",
       "      <td>1.513906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-16</th>\n",
       "      <td>0.538600</td>\n",
       "      <td>1.273768</td>\n",
       "      <td>0.667876</td>\n",
       "      <td>-0.969206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-23</th>\n",
       "      <td>1.676091</td>\n",
       "      <td>-0.817649</td>\n",
       "      <td>0.050188</td>\n",
       "      <td>1.951312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-05-30</th>\n",
       "      <td>3.260383</td>\n",
       "      <td>0.963301</td>\n",
       "      <td>1.201206</td>\n",
       "      <td>-1.852001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Colorado     Texas  New York      Ohio\n",
       "2001-05-02 -0.006045  0.490094 -0.277186 -0.707213\n",
       "2001-05-09 -0.560107  2.735527  0.927335  1.513906\n",
       "2001-05-16  0.538600  1.273768  0.667876 -0.969206\n",
       "2001-05-23  1.676091 -0.817649  0.050188  1.951312\n",
       "2001-05-30  3.260383  0.963301  1.201206 -1.852001"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slicing\n",
    "long_df.loc['5-2001'] # get all dates in May 2001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2.2 Time Series with Duplicate Indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    0\n",
       "2000-01-02    1\n",
       "2000-01-02    2\n",
       "2000-01-02    3\n",
       "2000-01-03    4\n",
       "dtype: int32"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in some applications, there may be multiple data observations falling on a particular timestamp\n",
    "\n",
    "dates = pd.DatetimeIndex(['1/1/2000', '1/2/2000', '1/2/2000', '1/2/2000', '1/3/2000'])\n",
    "dup_ts = pd.Series(np.arange(5), index=dates)\n",
    "dup_ts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can tell that the index is not unique by checking its 'is_unique' property\n",
    "dup_ts.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "----------------------------\n",
      "2000-01-02    1\n",
      "2000-01-02    2\n",
      "2000-01-02    3\n",
      "dtype: int32\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# indexing into this time series will now either produce scalar values or slices \n",
    "# depending on whether a timestamp is duplicated\n",
    "\n",
    "print(dup_ts['1/3/2000']) # not duplicated\n",
    "print('----------------------------')\n",
    "print(dup_ts['1/2/2000']) # duplicated\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01    0.0\n",
      "2000-01-02    2.0\n",
      "2000-01-03    4.0\n",
      "dtype: float64\n",
      "----------------------------\n",
      "2000-01-01    1\n",
      "2000-01-02    3\n",
      "2000-01-03    1\n",
      "dtype: int64\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# suppose you wanted to aggregate the data having non-unique timestamps\n",
    "# one way to do this is to use groupby() and pass level=0\n",
    "\n",
    "grouped = dup_ts.groupby(level=0)\n",
    "print(grouped.mean())\n",
    "print('----------------------------')\n",
    "print(grouped.count())\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.3 Date Ranges, Frequencies, and Shifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.resample.DatetimeIndexResampler object at 0x000001900427DEE0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generic time series in pandas are assumed to be irregular\n",
    "# that is, they have no fixed frequency\n",
    "# however, it's often desirable to work relative to a fixed frequency\n",
    "# even if that means introducing missing values into a time series\n",
    "\n",
    "# fortunately pandas has a full suite of standard time series frequencies and tools \n",
    "# for: resampling, inferring frequencies, and generating fixed-frequency date ranges \n",
    "\n",
    "# for example, you can convert the sample time series to be fixed daily frequency by calling resample()\n",
    "resampler = ts.resample('D') # 'D' means daily frequency\n",
    "\n",
    "resampler # works like a groupby() object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3.1 Generating Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',\n",
       "               '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',\n",
       "               '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',\n",
       "               '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',\n",
       "               '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20',\n",
       "               '2012-04-21', '2012-04-22', '2012-04-23', '2012-04-24',\n",
       "               '2012-04-25', '2012-04-26', '2012-04-27', '2012-04-28',\n",
       "               '2012-04-29', '2012-04-30', '2012-05-01', '2012-05-02',\n",
       "               '2012-05-03', '2012-05-04', '2012-05-05', '2012-05-06',\n",
       "               '2012-05-07', '2012-05-08', '2012-05-09', '2012-05-10',\n",
       "               '2012-05-11', '2012-05-12', '2012-05-13', '2012-05-14',\n",
       "               '2012-05-15', '2012-05-16', '2012-05-17', '2012-05-18',\n",
       "               '2012-05-19', '2012-05-20', '2012-05-21', '2012-05-22',\n",
       "               '2012-05-23', '2012-05-24', '2012-05-25', '2012-05-26',\n",
       "               '2012-05-27', '2012-05-28', '2012-05-29', '2012-05-30',\n",
       "               '2012-05-31', '2012-06-01'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# while I used it previously without explanation\n",
    "# pandas.date_range() is responsible for generating a 'DatetimeIndex' with an indicated length according to a particular frequency\n",
    "\n",
    "index =  pd.date_range('2012-04-01', '2012-06-01')\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',\n",
      "               '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',\n",
      "               '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',\n",
      "               '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',\n",
      "               '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "----------------------------\n",
      "DatetimeIndex(['2012-05-13', '2012-05-14', '2012-05-15', '2012-05-16',\n",
      "               '2012-05-17', '2012-05-18', '2012-05-19', '2012-05-20',\n",
      "               '2012-05-21', '2012-05-22', '2012-05-23', '2012-05-24',\n",
      "               '2012-05-25', '2012-05-26', '2012-05-27', '2012-05-28',\n",
      "               '2012-05-29', '2012-05-30', '2012-05-31', '2012-06-01'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "# by default, date_range() generates daily timestamps\n",
    "# if you pass only a start or end date, you must pass a number of periods to generate\n",
    "print(pd.date_range(start='2012-04-01', periods=20))\n",
    "print('----------------------------')\n",
    "print(pd.date_range(end='2012-06-01', periods=20))\n",
    "print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-28',\n",
       "               '2000-05-31', '2000-06-30', '2000-07-31', '2000-08-31',\n",
       "               '2000-09-29', '2000-10-31', '2000-11-30'],\n",
       "              dtype='datetime64[ns]', freq='BM')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the start and end dates defines strict boundaries for the generated date index\n",
    "# for example, if you wanted a date index containing the last business day of each month\n",
    "# you would pass the 'BM' frequency (business end of month) \n",
    "# and only dates falling on or inside the date interval will be included\n",
    "\n",
    "pd.date_range('2000-01-01', '2000-12-01', freq='BM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-05-12 12:56:31', '2012-05-13 12:56:31',\n",
       "               '2012-05-14 12:56:31', '2012-05-15 12:56:31',\n",
       "               '2012-05-16 12:56:31'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date_range() by default preserves the time (if any) of the start or end timestamp\n",
    "\n",
    "pd.date_range('2012-05-12 12:56:31', periods=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-05-02', '2012-05-03', '2012-05-04', '2012-05-05',\n",
       "               '2012-05-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sometimes you will have start or end dates with time information \n",
    "# but want to generate a set of timestamps 'normalized' to midnight as a convention\n",
    "# to do this, there is a 'normalize' option\n",
    "\n",
    "pd.date_range('2012-05-02 12:56:31', periods=5, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3.2 Frequencies and Date Offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Hour>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequencies in pandas are composed of a 'base frequency' and a multiplier\n",
    "# base frequencies are typically reffered to by a string alias\n",
    "# for each base frequency, there is an object defined generally referred to as a 'date offset'\n",
    "\n",
    "# for example, hourly frequency can be represeneted with the 'Hour' class\n",
    "from pandas.tseries.offsets import Hour, Minute\n",
    "\n",
    "hour = Hour()\n",
    "hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4 * Hours>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can define a multiple of an offset by passing an integer\n",
    "\n",
    "four_hours = Hour(4)\n",
    "four_hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 04:00:00',\n",
       "               '2000-01-01 08:00:00', '2000-01-01 12:00:00',\n",
       "               '2000-01-01 16:00:00', '2000-01-01 20:00:00',\n",
       "               '2000-01-02 00:00:00', '2000-01-02 04:00:00',\n",
       "               '2000-01-02 08:00:00', '2000-01-02 12:00:00',\n",
       "               '2000-01-02 16:00:00', '2000-01-02 20:00:00',\n",
       "               '2000-01-03 00:00:00'],\n",
       "              dtype='datetime64[ns]', freq='4H')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in most applications, you would never need to explicitly create one of these objects\n",
    "# instead, using a string alias like 'H' or '4H'\n",
    "# putting an integer before the base frequency creates a multiple\n",
    "\n",
    "pd.date_range('2000-01-01', '2000-01-03', freq='4H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<150 * Minutes>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# many offsets can be combined together using addition\n",
    "\n",
    "Hour(2) + Minute(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 01:30:00',\n",
       "               '2000-01-01 03:00:00', '2000-01-01 04:30:00',\n",
       "               '2000-01-01 06:00:00', '2000-01-01 07:30:00',\n",
       "               '2000-01-01 09:00:00', '2000-01-01 10:30:00',\n",
       "               '2000-01-01 12:00:00', '2000-01-01 13:30:00'],\n",
       "              dtype='datetime64[ns]', freq='90T')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarly, you can pass frequency strings that will effectively be parsed to the same expression\n",
    "\n",
    "pd.date_range('2000-01-01', periods=10, freq='1h30min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some frequencies describe points in time that are not evenly spaced\n",
    "# for example, 'M' (calendar month end) depends on the number of days in a month \n",
    "# and 'BM' (last business day/weekday of month) depends on whether the month ends on a weekend or not\n",
    "# we refer to these as 'anchored offset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3.3 Week of month dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Timestamp('2012-01-20 00:00:00', freq='WOM-3FRI'),\n",
       " Timestamp('2012-02-17 00:00:00', freq='WOM-3FRI'),\n",
       " Timestamp('2012-03-16 00:00:00', freq='WOM-3FRI'),\n",
       " Timestamp('2012-04-20 00:00:00', freq='WOM-3FRI'),\n",
       " Timestamp('2012-05-18 00:00:00', freq='WOM-3FRI'),\n",
       " Timestamp('2012-06-15 00:00:00', freq='WOM-3FRI'),\n",
       " Timestamp('2012-07-20 00:00:00', freq='WOM-3FRI'),\n",
       " Timestamp('2012-08-17 00:00:00', freq='WOM-3FRI')]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one useful frequency class is \"week of month\", starting with WOM\n",
    "# this enables you to get dates like the third friday of each month \n",
    "\n",
    "rng = pd.date_range('2012-01-01', '2012-09-01', freq='WOM-3FRI')\n",
    "list(rng) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3.4 Shifting (Leading and Lagging) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31   -0.066748\n",
       "2000-02-29    0.838639\n",
       "2000-03-31   -0.117388\n",
       "2000-04-30   -0.517795\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'shifting' refers to moving data backward and foward through time\n",
    "# both Series and DataFrame have a shift() method for doing naive shifts foward and backward, leaving the index unmodified\n",
    "# when we shift like this, missing data is introduced either at the start or the end of the time series\n",
    "\n",
    "ts = pd.Series(np.random.randn(4), index=pd.date_range('1/1/2000', periods=4, freq='M'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-31         NaN\n",
      "2000-02-29         NaN\n",
      "2000-03-31   -0.066748\n",
      "2000-04-30    0.838639\n",
      "Freq: M, dtype: float64\n",
      "------------------------\n",
      "2000-01-31   -0.117388\n",
      "2000-02-29   -0.517795\n",
      "2000-03-31         NaN\n",
      "2000-04-30         NaN\n",
      "Freq: M, dtype: float64\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "print(ts.shift(2)) # shift the data foward 2 index\n",
    "print('------------------------')\n",
    "print(ts.shift(-2)) # shift the data backward 2 index\n",
    "print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31          NaN\n",
       "2000-02-29   -13.564241\n",
       "2000-03-31    -1.139975\n",
       "2000-04-30     3.410958\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a common use of shift() is computing percent changes in a time series or multiple time series as DataFrame columns \n",
    "\n",
    "ts / ts.shift(1) - 1 # percent changes formula: a/b - 1 = (a-b)/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-03-31   -0.066748\n",
       "2000-04-30    0.838639\n",
       "2000-05-31   -0.117388\n",
       "2000-06-30   -0.517795\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# because naive shifts leave index unmodified, some data is discarded\n",
    "# thus, if the frequency is known, it can be passed to shift() to advance the timestamps instead of simply the data\n",
    "\n",
    "ts.shift(2, freq='M') # index also shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-02-03   -0.066748\n",
      "2000-03-03    0.838639\n",
      "2000-04-03   -0.117388\n",
      "2000-05-03   -0.517795\n",
      "dtype: float64\n",
      "------------------------\n",
      "2000-01-31 01:30:00   -0.066748\n",
      "2000-02-29 01:30:00    0.838639\n",
      "2000-03-31 01:30:00   -0.117388\n",
      "2000-04-30 01:30:00   -0.517795\n",
      "dtype: float64\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# other frequencies can be passed, too, giving you some flexibility in how to lead and lag the data\n",
    "\n",
    "print(ts.shift(3, freq='D')) # shift 3 days from the current time, then continue with freq='M'\n",
    "print('------------------------')\n",
    "print(ts.shift(1, freq='90T')) # shift 90 minutes from the current time, then continue with freq='M'\n",
    "print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3.5 Shifting dates with offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-11-20 00:00:00')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the pandas date offsets can also be used with datetime() or 'Timestamp' object\n",
    "\n",
    "from pandas.tseries.offsets import Day, MonthEnd\n",
    "\n",
    "now = datetime(2011, 11, 17)\n",
    "now + 3 * Day()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-11-30 00:00:00\n",
      "2011-12-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# if you add an anchored offset like MonthEnd\n",
    "# the first increment will \"roll foward\" a date to the next date according to the frequency rule\n",
    "\n",
    "print(now + MonthEnd())\n",
    "print(now + MonthEnd(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-11-30 00:00:00\n",
      "2011-10-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# anchored offsets can explicitly \"roll\" dates foward or backward \n",
    "# by simply using their rollfoward() and rollback() methods, respectively\n",
    "\n",
    "offset = MonthEnd()\n",
    "print(offset.rollforward(now))\n",
    "print(offset.rollback(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-15   -0.116696\n",
       "2000-01-19    2.389645\n",
       "2000-01-23   -0.932454\n",
       "2000-01-27   -0.229331\n",
       "2000-01-31   -1.140330\n",
       "                ...   \n",
       "2000-03-15    0.997747\n",
       "2000-03-19    0.870955\n",
       "2000-03-23   -0.991253\n",
       "2000-03-27    0.151699\n",
       "2000-03-31    1.266151\n",
       "Freq: 4D, Length: 20, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a creative use of date offsets is to use these methods with groupby()\n",
    "\n",
    "ts = pd.Series(np.random.randn(20),\n",
    "               index=pd.date_range('1/15/2000', periods=20, freq='4d'))\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31   -0.005833\n",
       "2000-02-29    0.015894\n",
       "2000-03-31    0.150209\n",
       "dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.groupby(offset.rollforward).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31   -0.005833\n",
       "2000-02-29    0.015894\n",
       "2000-03-31    0.150209\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of course, an easier and faster way to do this is using resample()\n",
    "\n",
    "ts.resample('M').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.4 Time Zone Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# working with time zones is generally considered one of the most unpleasant parts of time series manipulation\n",
    "# as a result, many time series users choose to work with time series in 'coordinated universal time' or UTC\n",
    "# which is the successor to Greenwich Mean Time and is the current international standard\n",
    "# time zones are expressed as offsets from UTC\n",
    "\n",
    "# in python, time zone information comes from the third-party 'pytz' library (installable with pip or conda)\n",
    "# which exposes the 'Olson database', a compilation of world time zone information\n",
    "# this is especially important for historical data \n",
    "# because the 'daylight saving time' (DST) transition dates have been changed numerous times \n",
    "# depending on the whim of local government \n",
    "\n",
    "# for detailed information about the 'pytz' library, you'll need to look at the library's documentation\n",
    "# as far as this book is concerned, pandas wraps pytz's functionality so you can ignore its API outside of the time zone names\n",
    "# time zone names can be find interactively and in the docs\n",
    "\n",
    "import pytz\n",
    "pytz.common_timezones[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get a time zone object from 'pytz', use pytz.timezone()\n",
    "# methods in pandas will accept either time zone names or these objects\n",
    "\n",
    "tz = pytz.timezone('America/New_York')\n",
    "tz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4.1 Time Zone Localization and Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 09:30:00   -0.202469\n",
       "2012-03-10 09:30:00    0.050718\n",
       "2012-03-11 09:30:00    0.639869\n",
       "2012-03-12 09:30:00    0.597594\n",
       "2012-03-13 09:30:00   -0.797246\n",
       "2012-03-14 09:30:00    0.472879\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by default, time series in pandas are 'time zone naive'\n",
    "\n",
    "rng = pd.date_range('3/9/2012 9:30', periods=6, freq='D')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# the index's tz is None\n",
    "print(ts.index.tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-09 00:00:00+00:00', '2012-03-10 00:00:00+00:00',\n",
       "               '2012-03-11 00:00:00+00:00', '2012-03-12 00:00:00+00:00',\n",
       "               '2012-03-13 00:00:00+00:00', '2012-03-14 00:00:00+00:00',\n",
       "               '2012-03-15 00:00:00+00:00', '2012-03-16 00:00:00+00:00',\n",
       "               '2012-03-17 00:00:00+00:00', '2012-03-18 00:00:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq='D')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# date ranges can be generated with a time zone set\n",
    "\n",
    "pd.date_range('3/9/2012', periods=10, freq='D', tz='UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-03-09 09:30:00+00:00   -0.202469\n",
      "2012-03-10 09:30:00+00:00    0.050718\n",
      "2012-03-11 09:30:00+00:00    0.639869\n",
      "2012-03-12 09:30:00+00:00    0.597594\n",
      "2012-03-13 09:30:00+00:00   -0.797246\n",
      "2012-03-14 09:30:00+00:00    0.472879\n",
      "Freq: D, dtype: float64\n",
      "-----------------------------------------\n",
      "DatetimeIndex(['2012-03-09 09:30:00+00:00', '2012-03-10 09:30:00+00:00',\n",
      "               '2012-03-11 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n",
      "               '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', freq='D')\n",
      "-----------------------------------------\n",
      "2012-03-09 04:30:00-05:00   -0.202469\n",
      "2012-03-10 04:30:00-05:00    0.050718\n",
      "2012-03-11 05:30:00-04:00    0.639869\n",
      "2012-03-12 05:30:00-04:00    0.597594\n",
      "2012-03-13 05:30:00-04:00   -0.797246\n",
      "2012-03-14 05:30:00-04:00    0.472879\n",
      "Freq: D, dtype: float64\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# conversion from navie to 'localized' is handled by the tz_localize() method\n",
    "\n",
    "ts_utc = ts.tz_localize('UTC')\n",
    "print(ts_utc)\n",
    "print('-----------------------------------------')\n",
    "print(ts_utc.index)\n",
    "print('-----------------------------------------')\n",
    "\n",
    "# once a time series has been localized to a particular time zone\n",
    "# it can be converted to another time zone with tz_convert()\n",
    "\n",
    "print(ts_utc.tz_convert('America/New_York'))\n",
    "print('-----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-03-09 14:30:00+00:00   -0.202469\n",
      "2012-03-10 14:30:00+00:00    0.050718\n",
      "2012-03-11 13:30:00+00:00    0.639869\n",
      "2012-03-12 13:30:00+00:00    0.597594\n",
      "2012-03-13 13:30:00+00:00   -0.797246\n",
      "2012-03-14 13:30:00+00:00    0.472879\n",
      "dtype: float64\n",
      "-----------------------------------------\n",
      "2012-03-09 15:30:00+01:00   -0.202469\n",
      "2012-03-10 15:30:00+01:00    0.050718\n",
      "2012-03-11 14:30:00+01:00    0.639869\n",
      "2012-03-12 14:30:00+01:00    0.597594\n",
      "2012-03-13 14:30:00+01:00   -0.797246\n",
      "2012-03-14 14:30:00+01:00    0.472879\n",
      "dtype: float64\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# in the case of the preceeding time series\n",
    "# which straddles a DST transition in the America/New_York time zone\n",
    "# we could localize to EST and convert to, say UTC or Berlin time\n",
    "\n",
    "ts_eastern = ts.tz_localize('America/New_York')\n",
    "print(ts_eastern.tz_convert('UTC'))\n",
    "print('-----------------------------------------')\n",
    "print(ts_eastern.tz_convert('Europe/Berlin'))\n",
    "print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4.2 Operations with Time Zone-Aware Timestamp Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-03-11 23:00:00-0500', tz='America/New_York')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to time series and date ranges\n",
    "# individual Timestamp objects similarly can be localized from naive to time zone-aware \n",
    "# and converted from one time zone to another\n",
    "\n",
    "stamp = pd.Timestamp('2011-03-12 04:00')\n",
    "stamp_utc = stamp.tz_localize('utc')\n",
    "stamp_utc.tz_convert('America/New_York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011-03-12 04:00:00+03:00\n",
      "-----------------------------------------\n",
      "1299902400000000000\n",
      "1299902400000000000\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# you can also pass a time zone when creating the Timestamp\n",
    "\n",
    "start_moscow = pd.Timestamp('2011-03-12 04:00', tz='Europe/Moscow')\n",
    "print(start_moscow)\n",
    "print('-----------------------------------------')\n",
    "\n",
    "# time zone-aware Timestamp objects internally store a UTC timestamp value as nanoseconds since the UNIX epoch (January 1, 1970)\n",
    "# this UTC value is invariant between time zone conversions\n",
    "print(stamp_utc.value)\n",
    "print(stamp_utc.tz_convert('America/New_York').value)\n",
    "print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-03-12 01:30:00-04:00\n",
      "2012-03-12 02:30:00-04:00\n",
      "-----------------------------------------\n",
      "2012-11-04 00:30:00-04:00\n",
      "2012-11-04 01:30:00-05:00\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# when performing time arithmetic using pandas's DateOffset objects\n",
    "# pandas respects daylight saving time transitions where possible\n",
    "# here we construct time stamps that occur right before DST transitions (forward and backward)\n",
    "\n",
    "from pandas.tseries.offsets import Hour \n",
    "\n",
    "# first, 30 minutes before transitioning to DST\n",
    "stamp = pd.Timestamp('2012-03-12 01:30', tz='US/Eastern')\n",
    "print(stamp)\n",
    "print(stamp + Hour())\n",
    "print('-----------------------------------------')\n",
    "\n",
    "# then, 90 minutes before transitioning out of DST\n",
    "stamp = pd.Timestamp('2012-11-04 00:30', tz='US/Eastern')\n",
    "print(stamp)\n",
    "print(stamp + 2 * Hour())\n",
    "print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4.3 Operations Between Different Time Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-07 09:30:00    0.522356\n",
       "2012-03-08 09:30:00   -0.546348\n",
       "2012-03-09 09:30:00   -0.733537\n",
       "2012-03-12 09:30:00    1.302736\n",
       "2012-03-13 09:30:00    0.022199\n",
       "2012-03-14 09:30:00    0.364287\n",
       "2012-03-15 09:30:00   -0.922839\n",
       "2012-03-16 09:30:00    0.312656\n",
       "2012-03-19 09:30:00   -1.128497\n",
       "2012-03-20 09:30:00   -0.333488\n",
       "Freq: B, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if two time series with different time zones are combined, the result will be UTC\n",
    "# since the timestamps are stored under the hood in UTC\n",
    "# this is a straightforward operation and requires no conversion to happen\n",
    "\n",
    "rng = pd.date_range('3/7/2012 9:30', periods=10, freq='B')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-07 09:30:00+00:00', '2012-03-08 09:30:00+00:00',\n",
       "               '2012-03-09 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n",
       "               '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',\n",
       "               '2012-03-15 09:30:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq=None)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = ts[:7].tz_localize('Europe/London')\n",
    "ts2 = ts1[2:].tz_convert('Europe/Moscow')\n",
    "result = ts1 + ts2\n",
    "result.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.5 Periods and Period Arithmetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2007', 'A-DEC')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Periods' represent timespans, like days, months, quarters, or years\n",
    "# the 'Period' class represents this data type, requiring a string or integer and a frequency\n",
    "\n",
    "p = pd.Period(2007, freq='A-DEC')\n",
    "p # in this case, the Period object represents the full timespan from (Jan 1, 2007) to (Dec 31, 2007) inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Period('2012', 'A-DEC'), Period('2005', 'A-DEC')]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conveniently, adding and subtracting integers from periods has the effect of shifting by their frequency\n",
    "\n",
    "[p + 5, p - 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7 * YearEnds: month=12>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if two periods have the same frequency, their difference is the number of units between them\n",
    "\n",
    "pd.Period('2014', freq='A-DEC') - p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '2000-06'], dtype='period[M]')\n",
      "-----------------------------------------\n",
      "2000-01   -0.514551\n",
      "2000-02   -0.559782\n",
      "2000-03   -0.783408\n",
      "2000-04   -1.797685\n",
      "2000-05   -0.172670\n",
      "2000-06    0.680215\n",
      "Freq: M, dtype: float64\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# regular ranges of periods can be constructed with the period_range() function\n",
    "\n",
    "rng = pd.period_range('2000-01-01', '2000-06-03', freq='M')\n",
    "print(rng)\n",
    "print('-----------------------------------------')\n",
    "\n",
    "# the 'PeriodIndex' class stores a sequence of periods and can serve as an axis index in any pandas data structure\n",
    "s = pd.Series(np.random.randn(6), index=rng)\n",
    "print(s)\n",
    "print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2001Q3', '2002Q2', '2003Q1'], dtype='period[Q-DEC]')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you have an array of strings, you can also use the 'PeriodIndex' class\n",
    "\n",
    "values = ['2001Q3', '2002Q2', '2003Q1']\n",
    "index = pd.PeriodIndex(values, freq='Q-DEC')\n",
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5.1 Period Frequency Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Period('2007', 'A-DEC'), Period('2007-01', 'M'), Period('2007-12', 'M')]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Periods and 'PeriodIndex' objects can be converted to another frequency with their asfreq() method\n",
    "\n",
    "# suppose we had an annual period \n",
    "# and wanted to convert it into a monthly period either at the start or the end of the year\n",
    "p = pd.Period('2007', freq='A-DEC')\n",
    "[p, p.asfreq('M', how='start'), p.asfreq('M', how='end')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Period('2007', 'A-JUN'), Period('2006-07', 'M'), Period('2007-06', 'M')]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a 'fiscal year' ending on a month other than December, the corresponding monthly subperiods are different\n",
    "\n",
    "p = pd.Period('2007', freq='A-JUN')\n",
    "[p, p.asfreq('M', 'start'), p.asfreq('M', 'end')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2008', 'A-JUN')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when you are converting from high to low frequency\n",
    "# pandas determines the super-period depending on where the subperiod \"belongs\"\n",
    "\n",
    "# in 'A-JUN' frequency, the month 'Aug-2007' is acutally part of the '2008' period\n",
    "p = pd.Period('Aug-2007', 'M')\n",
    "p.asfreq('A-JUN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006    1.607578\n",
      "2007    0.200381\n",
      "2008   -0.834068\n",
      "2009   -0.302988\n",
      "Freq: A-DEC, dtype: float64\n",
      "-----------------------------------------\n",
      "2006-01    1.607578\n",
      "2007-01    0.200381\n",
      "2008-01   -0.834068\n",
      "2009-01   -0.302988\n",
      "Freq: M, dtype: float64\n",
      "-----------------------------------------\n",
      "2006-12-29    1.607578\n",
      "2007-12-31    0.200381\n",
      "2008-12-31   -0.834068\n",
      "2009-12-31   -0.302988\n",
      "Freq: B, dtype: float64\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# whole 'PeriodIndex' objects or time series can be similarly converted with the same semantics\n",
    "\n",
    "rng = pd.period_range('2006', '2009', freq='A-DEC')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "print(ts)\n",
    "print('-----------------------------------------')\n",
    "print(ts.asfreq('M', how='start'))\n",
    "print('-----------------------------------------')\n",
    "\n",
    "# here, the annual periods are replaced with monthly periods corresponding to the first month falling within each annual period\n",
    "# if we instead wanted the last business day of each year\n",
    "# we can use the 'B' frequency and indicate that we want the end of the period\n",
    "print(ts.asfreq('B', how='end'))\n",
    "print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5.2 Quarterly Period Frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d4254fe60a3fb9e3622cd4e4c99072a21afdb57c0b00492bb3bfa4b8b6d22a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
